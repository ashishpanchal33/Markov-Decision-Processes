{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ce4340-a000-4843-9ab8-aea8da039b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import TimeLimit\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gym.envs.classic_control import MountainCarEnv\n",
    "from typing import List, Optional\n",
    "from contextlib import closing\n",
    "from io import StringIO\n",
    "from os import path\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#import gymnasium as gym\n",
    "#from gymnasium import Env, spaces, utils\n",
    "#from gymnasium.envs.toy_text.utils import categorical_sample\n",
    "#from gymnasium.error import DependencyNotInstalled\n",
    "#from gymnasium.utils import seeding\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.envs.classic_control import utils\n",
    "from gym.error import DependencyNotInstalled\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d791d78-8a17-4eea-bcaa-0904d9bced78",
   "metadata": {},
   "source": [
    "# new environment for updated reset staps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d671187-5522-4bca-80ea-a6d272382366",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ExtendedMountainCarEnv(MountainCarEnv):\n",
    "    \n",
    "    def reset(\n",
    "        self,\n",
    "        *,\n",
    "        seed: Optional[int] = None,\n",
    "        options: Optional[dict] = None,\n",
    "        state: Optional[list] = None,\n",
    "    ):\n",
    "        super().reset(seed=seed)\n",
    "        # Note that if you use custom reset bounds, it may lead to out-of-bound\n",
    "        # state/observations.\n",
    "        low, high = utils.maybe_parse_reset_bounds(options, -0.6, -0.4)\n",
    "        \n",
    "        #print(state)\n",
    "        \n",
    "        if type(state) !=None:\n",
    "            \n",
    "            self.state = state\n",
    "        else:\n",
    "            self.state = np.array([self.np_random.uniform(low=low, high=high), 0])\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        return np.array(self.state, dtype=np.float32), {}    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0d1542-7c7a-4759-9216-3fb5dfb047c9",
   "metadata": {},
   "source": [
    "# descritization modules and transition matrix generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "be837bec-8b70-40f1-bdc1-3d3140e73cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#c\n",
    "max_episode_steps = 200\n",
    "env = ExtendedMountainCarEnv(#render_mode = 'human'\n",
    "                            )\n",
    "\n",
    "\n",
    "ExtendedMountainCarEnv_ref = gym.register(\n",
    "    id=\"MountainCarEnv-v1_cust\",\n",
    "    entry_point=ExtendedMountainCarEnv,\n",
    ")\n",
    "\n",
    "env = gym.make('MountainCarEnv-v1_cust', render_mode=None,max_episode_steps=max_episode_steps)\n",
    "\n",
    "\n",
    "\n",
    "env.spec.reward_threshold =-110.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Discretize the state space\n",
    "num_states_per_dim = 5\n",
    "\n",
    "\n",
    "def discretize_environment(env,dim = 5):\n",
    "\n",
    "\n",
    "\n",
    "    low, high = env.observation_space.low, env.observation_space.high\n",
    "\n",
    "\n",
    "    bin_width = (high - low) / (dim-1)\n",
    "    state_space = np.zeros((dim, dim, high.shape[0] ))\n",
    "\n",
    "    \n",
    "\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            state_space[i, j] = low[0] + i * bin_width[0], low[1] + j * bin_width[1]\n",
    "    state_space.shape\n",
    "    \n",
    "    \n",
    "    return low,high,bin_width,state_space\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mapper_state(state, seriaized):\n",
    "    return np.where(\n",
    "(seriaized == state).sum(axis =1) == 2)[0][0]\n",
    "\n",
    "\n",
    "# Discretize state\n",
    "def discretize_state(state,low ,bin_width ,state_space ):\n",
    "    state_adj = low + bin_width*((state - low)//bin_width)\n",
    "    state_adj = state_space[np.all(state_space.astype('float16') ==  (state_adj).astype('float16'),axis=2)][0]\n",
    "    return state_adj\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_P(env=env,dim = [5,],pickle_name='random_name',save = True, base_addr = r'./environments/',iter_=50,version=1,\n",
    "               original = False,verbose = False,run_trial = 10, exploration_verions = 1):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    packages = { i:dict({}) for i in dim}\n",
    "    \n",
    "    \n",
    "    for i in dim:\n",
    "        \n",
    "        low,high,bin_width,state_space = discretize_environment(env,dim = i)\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        #env = gym.make('MountainCar-v0',render_mode='human')\n",
    "\n",
    "        seriaized = state_space.reshape(-1,2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        nA = env.action_space.n\n",
    "        num_states_per_dim = i\n",
    "        \n",
    "        nS = num_states_per_dim*num_states_per_dim\n",
    "        P = {s: {a: [] for a in range(nA)} for s in range(nS)}\n",
    "        #P\n",
    "        num_states = [num_states_per_dim,num_states_per_dim]\n",
    "        # Initialize the state-action count\n",
    "        # Initialize the transition matrix\n",
    "        transition_matrix = np.zeros((nS, env.action_space.n, nS))\n",
    "\n",
    "        #reward_matrix = np.zeros((nS, env.action_space.n, nS))\n",
    "\n",
    "\n",
    "        terminate_matrix = np.zeros((nS))\n",
    "        # Initialize the state-action count\n",
    "        state_action_count = np.zeros((nS, env.action_space.n))\n",
    "\n",
    "\n",
    "        packages[i] = dict(\n",
    "        \n",
    "\n",
    "                            low = low,\n",
    "                            high = high,\n",
    "                            bin_width = bin_width,\n",
    "                            state_space = state_space,\n",
    "                            seriaized = seriaized\n",
    "                            ,nA = nA\n",
    "                            ,nS = nS\n",
    "                            ,P = P\n",
    "                            ,num_states = num_states\n",
    "                            ,transition_matrix = transition_matrix\n",
    "                            ,terminate_matrix = terminate_matrix\n",
    "                            ,state_action_count = state_action_count                \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                            )        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "    # Estimate the transition probabilities\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    for episode in range(iter_):\n",
    "        \n",
    "        \n",
    "        \n",
    "        if exploration_verions ==1:\n",
    "\n",
    "            if original:\n",
    "                state = env.reset()[0]\n",
    "            else:\n",
    "                \n",
    "                \n",
    "                state = env.reset(state = np.array([np.random.uniform(low=low[0], high=high[0]), np.random.uniform(low=low[1], high=high[1])]))[0]\n",
    "                \n",
    "                \n",
    "                #state = env.reset(state =packages[dim[-1]]['seriaized'][np.random.choice(len(packages[dim[-1]]['seriaized']) )] )[0]\n",
    "\n",
    "\n",
    "\n",
    "            #print(res)\n",
    "\n",
    "            done = False\n",
    "            truncated = False\n",
    "            steps = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            while not (done or truncated):\n",
    "\n",
    "                steps+=1\n",
    "                action = int(env.action_space.sample())\n",
    "                next_state, reward, done,truncated, info = env.step(action)\n",
    "                #next_state = discretize_state(next_state,low,bin_width,state_space)#discretize_state(next_state)\n",
    "\n",
    "\n",
    "\n",
    "                #print(state[0], state[1], action, next_state[0], next_state[1])\n",
    "\n",
    "                for i in dim:#packages.keys():\n",
    "\n",
    "                    state_1 = discretize_state(state,\n",
    "                                             packages[i]['low'],packages[i]['bin_width'],packages[i]['state_space'])#discretize_state(env.reset())\n",
    "\n",
    "                    next_state_1 = discretize_state(next_state,\n",
    "                                             packages[i]['low'],packages[i]['bin_width'],packages[i]['state_space'])\n",
    "\n",
    "                    s1 = mapper_state(state_1,packages[i]['seriaized'])\n",
    "                    s2 = mapper_state(next_state_1,packages[i]['seriaized'])\n",
    "                    packages[i]['transition_matrix'][s1, action, s2] += 1\n",
    "                    #reward_matrix[s1, action, s2] += reward\n",
    "                    packages[i]['terminate_matrix'][s2] += done\n",
    "                    packages[i]['state_action_count'][s1, action] += 1\n",
    "                state = next_state\n",
    "\n",
    "            if (verbose):\n",
    "                print(steps)\n",
    "            #env.render()\n",
    "        \n",
    "        else: # exploration_verions ==2:\n",
    "\n",
    "            for s_1 in packages[dim[-1]]['seriaized']:#range(packages[dim[-1]]['nS']):          \n",
    "\n",
    "                \n",
    "                for action in range(packages[dim[-1]]['nA']):\n",
    "                                    \n",
    "                    if original:\n",
    "                        state = env.reset()[0]\n",
    "                    else:\n",
    "                        \n",
    "                        \n",
    "                        try:\n",
    "                            state = env.reset(state =s_1)[0]#packages[dim[-1]]['seriaized'][s_1] )[0]\n",
    "                        except IOError:\n",
    "                            print()\n",
    "                        next_state, reward, done,truncated, info = env.step(action)\n",
    "                        \n",
    "                        \n",
    "                        for i in packages.keys():\n",
    "\n",
    "                            state_1 = discretize_state(state,\n",
    "                                                     packages[i]['low'],packages[i]['bin_width'],packages[i]['state_space'])#discretize_state(env.reset())\n",
    "\n",
    "                            next_state_1 = discretize_state(next_state,\n",
    "                                                     packages[i]['low'],packages[i]['bin_width'],packages[i]['state_space'])\n",
    "\n",
    "                            s1 = mapper_state(state_1,packages[i]['seriaized'])\n",
    "                            s2 = mapper_state(next_state_1,packages[i]['seriaized'])\n",
    "                            packages[i]['transition_matrix'][s1, action, s2] += 1\n",
    "                            #reward_matrix[s1, action, s2] += reward\n",
    "                            packages[i]['terminate_matrix'][s2] += done\n",
    "                            packages[i]['state_action_count'][s1, action] += 1\n",
    "                        state = next_state                        \n",
    "\n",
    "                        \n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    search_func = lambda x,y: ([[x,y-1],[x,y+1],[x-1,y],[x+1,y]])\n",
    "\n",
    "  \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    for l in dim:    \n",
    "\n",
    "        (nS,nA,state_action_count, transition_matrix,\n",
    "        \n",
    "        terminate_matrix\n",
    "        ) = (\n",
    "        \n",
    "        \n",
    "        packages[l]['nS']\n",
    "        ,packages[l]['nA']\n",
    "        \n",
    "        ,packages[l]['state_action_count']\n",
    "        , packages[l]['transition_matrix']\n",
    "        \n",
    "        , packages[l]['terminate_matrix']\n",
    "        \n",
    "        \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for i in range(nS):\n",
    "            for j in range(nA):\n",
    "\n",
    "                if packages[l]['state_action_count'][i,j]!=0:\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                        #if version==1:\n",
    "                        #    for k in range(nS):\n",
    "                        #        if packages[l]['transition_matrix'][i,j,k]!=0:\n",
    "                        #            reward_matrix[i,j,\n",
    "                        #                k] /= packages[l]['transition_matrix'][i,j,k]\n",
    "\n",
    "                        packages[l]['transition_matrix'][i,j,\n",
    "                                    :] /= packages[l]['state_action_count'][i,j]\n",
    "\n",
    "\n",
    "\n",
    "        P_ = { i:\n",
    "               { \n",
    "\n",
    "                  j: [\n",
    "                   (packages[l]['transition_matrix'][i,j,k],k,-1 #reward_matrix[i,j,k]#\n",
    "                    , packages[l]['terminate_matrix'][k]>0  )\n",
    "\n",
    "                   for k in range(nS) if packages[l]['transition_matrix'][i,j,k]>0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                   ]\n",
    "\n",
    "\n",
    "\n",
    "                   for j in range(nA)}           for i in range(nS)}\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        not_don = True\n",
    "        \n",
    "        k=0\n",
    "        \n",
    "        gap = True\n",
    "        \n",
    "        \n",
    "        #running complex fill\n",
    "        \n",
    "        if version==1:\n",
    "        \n",
    "            for running in range(run_trial):\n",
    "\n",
    "\n",
    "\n",
    "                gap = False\n",
    "\n",
    "\n",
    "\n",
    "                for i in range(nS):\n",
    "                    for j in range(nA):  \n",
    "                        if len(P_[i][j]) == 0:\n",
    "\n",
    "\n",
    "                                for lam in search_func(i,j):\n",
    "                                    if (i in [0,nS-1]) or (j in [0,nA-1]):\n",
    "                                        pass#gap = True\n",
    "                                    elif len(P_[lam[0]][lam[1]]) == 0:\n",
    "                                        pass#gap = True\n",
    "\n",
    "                                    else:\n",
    "                                        P_[i][j] = P_[lam[0]][lam[1]]\n",
    "                            \n",
    "                            \n",
    "\n",
    "        for i in range(nS):\n",
    "            for j in range(nA):  \n",
    "                if len(P_[i][j]) == 0:\n",
    "                        P_[i][j] = [(1.0, -1, -1.0, True)]\n",
    "\n",
    "\n",
    "                                \n",
    "\n",
    "\n",
    "                        \n",
    "                \n",
    "                    \n",
    "                        \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        packages[l]['P'] = P_\n",
    "\n",
    "        \n",
    "\n",
    "    if save:\n",
    "        with open(base_addr+pickle_name+'_envP_config.pkl','wb') as fi:\n",
    "            pickle.dump(\n",
    "                                    packages\n",
    "\n",
    "                                    ,fi)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return packages\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "a37c1ee4-fd23-4966-8495-84f7804d10ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0', render_mode='None',max_episode_steps = 10)\n",
    "env._max_episode_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a231cd7-bb74-4435-9377-a07b8c6c3c63",
   "metadata": {},
   "source": [
    "# Generate Transition matrix and helpful data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "e230c1e3-674a-474e-aaf9-12d2c1906be5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#env = ExtendedMountainCarEnv(#render_mode = 'human'\n",
    "#                            )\n",
    "\n",
    "\n",
    "ExtendedMountainCarEnv_ref = gym.register(\n",
    "    id=\"MountainCarEnv-v1_cust\",\n",
    "    entry_point=ExtendedMountainCarEnv,\n",
    ")\n",
    "\n",
    "\n",
    "max_episode_steps = 200\n",
    "env = gym.make('MountainCarEnv-v1_cust', render_mode=None,max_episode_steps=max_episode_steps)\n",
    "\n",
    "env.spec.reward_threshold =-110.0\n",
    "\n",
    "\n",
    "\n",
    "resp_5 = generate_P(env=env,dim = [5,10,15,20,25,30]\n",
    "                    ,pickle_name='MountainCar',save = True, verbose = False,\n",
    "                    \n",
    "                    base_addr = r'./environment/',iter_=10000, original=False,version=1,run_trial=10,exploration_verions=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (experiments)",
   "language": "python",
   "name": "experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
